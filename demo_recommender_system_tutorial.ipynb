{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d54588-bdab-489e-bb5b-35294738ee86",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e49e8d12-e20f-409d-9a09-37256433bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint \n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import tensorflow_recommenders as tfrs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fde729-d1d7-464a-ad78-9392d893c7f7",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1cbdb4-b52f-4812-812d-f72266562cd4",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f961f02-cb24-4c56-b023-fda17978438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Datasets/online_retail_II.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d679ceeb-8e7a-4104-a35e-7939495be318",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d83156-2f1e-49f4-ab00-9e101636c77f",
   "metadata": {},
   "source": [
    "## drop unnecessory columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f414c825-28b9-441c-8aa2-260a77159ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = users_df.dropna()\n",
    "users_df = users_df[['Customer ID', 'Description']]\n",
    "help_ = users_df[['Description']].drop_duplicates()\n",
    "help_['product_id'] = [i+1 for i in range(help_.shape[0])]\n",
    "users_df = users_df.merge(help_, on='Description'\n",
    "                         ).drop('Description', axis=1\n",
    "                         ).rename(columns = {'Description' : 'product_id', 'Customer ID': 'user_id'})\n",
    "users_df.user_id = users_df.user_id.apply(lambda x: str(int(x)))\n",
    "users_df.product_id = users_df.product_id.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170dffd5-43ed-475e-a34e-5fdad2060aa7",
   "metadata": {},
   "source": [
    "## convert float nan to str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9774922a-2051-454d-b98d-2836971d7bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = users_df.sample(frac=1).reset_index(drop=True)\n",
    "products_df = users_df[['product_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67b4abe1-aada-4dff-bcbc-240f666dc36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_dataset = tf.data.Dataset.from_tensor_slices(dict(users_df))\n",
    "products_dataset = tf.data.Dataset.from_tensor_slices(dict(products_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d915bfe8-3875-487d-9b22-8f4742565e76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product_id': b'267', 'user_id': b'14606'}\n",
      "{'product_id': b'1601', 'user_id': b'14606'}\n",
      "{'product_id': b'324', 'user_id': b'14606'}\n",
      "{'product_id': b'2824', 'user_id': b'14606'}\n",
      "{'product_id': b'2506', 'user_id': b'14606'}\n",
      "{'product_id': b'196', 'user_id': b'14606'}\n",
      "{'product_id': b'918', 'user_id': b'14606'}\n",
      "{'product_id': b'88', 'user_id': b'14606'}\n",
      "{'product_id': b'686', 'user_id': b'14606'}\n",
      "{'product_id': b'631', 'user_id': b'14606'}\n",
      "{'product_id': b'363', 'user_id': b'14606'}\n",
      "{'product_id': b'1547', 'user_id': b'14606'}\n",
      "{'product_id': b'3208', 'user_id': b'14606'}\n",
      "{'product_id': b'2781', 'user_id': b'14606'}\n",
      "{'product_id': b'237', 'user_id': b'14606'}\n",
      "{'product_id': b'3402', 'user_id': b'14606'}\n",
      "{'product_id': b'1220', 'user_id': b'14606'}\n"
     ]
    }
   ],
   "source": [
    "for x in users_dataset.take(1000).as_numpy_iterator():\n",
    "    if x['user_id'] == b'14606':\n",
    "        pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555015ce-255f-42a5-b899-cc01f08039a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# implement recommender system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1dab7e-b161-418c-93f5-667705aba95d",
   "metadata": {},
   "source": [
    "# prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d611f26b-33fa-43ba-bc39-83db15f3cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class prepare_data:\n",
    "    \n",
    "    # Init\n",
    "    def __init__(self, users, products):\n",
    "        self.users = users\n",
    "        self.products = products\n",
    "    # keep useful elements\n",
    "    def keep_useful_elements(self):\n",
    "        self.users = self.users.map(lambda x: {\n",
    "                         'product_id' : x['product_id'],\n",
    "                         'user_id' : x['user_id'],\n",
    "                    })\n",
    "        self.products = self.products.map(lambda x: x['product_id'])\n",
    "        return self.users, self.products \n",
    "    \n",
    "    def train_test_generator(self, train_range=80_000, all_range=100_000):\n",
    "        tf.random.set_seed(42)\n",
    "        shuffled = self.users.shuffle(all_range, seed=42, reshuffle_each_iteration=False)\n",
    "        train = shuffled.take(train_range)\n",
    "        test = shuffled.skip(train_range).take(all_range - train_range)\n",
    "        return train, test\n",
    "    \n",
    "    def pass_unique(self):\n",
    "        product_ids = self.products.batch(1_000)\n",
    "        user_ids = self.users.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "        unique_product_ids = np.unique(np.concatenate(list(product_ids)))\n",
    "        unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "        return unique_product_ids, unique_user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dbc3f6f-7ad1-4ec1-8583-87d893bfc211",
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelAndLoss:\n",
    "    \n",
    "    def __init__(self, unique_product_ids, unique_user_ids, products):\n",
    "        self.unique_product_ids = unique_product_ids\n",
    "        self.unique_user_ids = unique_user_ids\n",
    "        self.products = products\n",
    "        # self.product_model = None\n",
    "    def implement_model(self, embedding_dimension = 32):\n",
    "            \n",
    "        # Here, we're going to use Keras preprocessing layers to first convert user ids to integers, and then convert those\n",
    "        # to user embeddings via an Embedding layer.\n",
    "        user_model = tf.keras.Sequential([\n",
    "          tf.keras.layers.StringLookup(\n",
    "              vocabulary=self.unique_user_ids, mask_token=None),\n",
    "          # We add an additional embedding to account for unknown tokens.\n",
    "          tf.keras.layers.Embedding(len(self.unique_user_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "        \n",
    "        # the candidate tower\n",
    "        self.product_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.StringLookup(\n",
    "          vocabulary=self.unique_product_ids, mask_token=None),\n",
    "        tf.keras.layers.Embedding(len(self.unique_product_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "        return user_model, self.product_model\n",
    "    \n",
    "    def metrics_loss(self, batch_size = 128):\n",
    "        metrics = tfrs.metrics.FactorizedTopK(\n",
    "          candidates= self.products.batch(batch_size).map(self.product_model)\n",
    "        )\n",
    "        task = tfrs.tasks.Retrieval(\n",
    "            metrics=metrics)\n",
    "        return task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f378713-7181-46f3-a551-c2a884c7c7b4",
   "metadata": {},
   "source": [
    "# full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "246ff110-713e-4332-b00b-79508af8c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class userProductModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self, user_model, product_model):\n",
    "        super().__init__()\n",
    "        self.product_model: tf.keras.Model = product_model\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        self.user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        # And pick out the product features and pass them into the product model,\n",
    "        # getting embeddings back.\n",
    "        self.positive_product_embeddings = self.product_model(features[\"product_id\"])\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(self.user_embeddings, self.positive_product_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af008fe-1c10-440b-8bc0-7e58d2189cd4",
   "metadata": {},
   "source": [
    "## fit and evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b93ff5e-8c90-444c-88e6-168ea3e01264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting and evaluating\n",
    "class fitAndEvaluateModel:\n",
    "    \n",
    "    def __init__(self, user_model, product_model, train, test):\n",
    "        self.user_model = user_model\n",
    "        self.product_model = product_model\n",
    "        self.model = None\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        \n",
    "    def create_model(self):\n",
    "        self.model = userProductModel(self.user_model, self.product_model) \n",
    "    \n",
    "    def compile_model(self):\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "    \n",
    "    def fit_model(self):\n",
    "        cached_train = train.shuffle(200_000).batch(8192).cache()\n",
    "        self.cached_test = test.batch(4096).cache()\n",
    "        self.model.fit(cached_train, epochs=10)\n",
    "        return self.model\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        self.model.evaluate(self.cached_test, return_dict=True)\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe65afa3-2265-4d3f-91a8-dc7611b2e842",
   "metadata": {},
   "source": [
    "# recommend item to user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ee1089b-b884-4080-afd8-150cdf883929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, products, product_model):\n",
    "    # Create a model that takes in raw query features, and\n",
    "    index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "    # recommends products out of the entire products dataset.\n",
    "    index.index_from_dataset(\n",
    "      tf.data.Dataset.zip((products.batch(100), products.batch(100).map(model.product_model)))\n",
    "    )\n",
    "\n",
    "    # Get recommendations.\n",
    "    _, titles = index(tf.constant([b\"13085\"]))\n",
    "    return titles, index\n",
    "    # print(f\"Recommendations for user 42: {titles[0, :3]}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee995adf-8712-405b-8158-f11548d05ac2",
   "metadata": {},
   "source": [
    "# call classes and functions to see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c12d3107-2bb1-4d5b-aba9-0da2f6974de6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings, info = tfds.load(\"movielens/100k-ratings\", split=\"train\", with_info = True)\n",
    "# for x in ratings.take(10000).as_numpy_iterator():\n",
    "#     if x['user_id'] == b'357':\n",
    "#         pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e34503-853f-4545-99c3-3919485ff7c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 1124s 112s/step - factorized_top_k/top_1_categorical_accuracy: 2.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 2.5000e-04 - factorized_top_k/top_10_categorical_accuracy: 3.0000e-04 - factorized_top_k/top_50_categorical_accuracy: 3.2500e-04 - factorized_top_k/top_100_categorical_accuracy: 3.2500e-04 - loss: 70205.3913 - regularization_loss: 0.0000e+00 - total_loss: 70205.3913\n",
      "Epoch 2/10\n"
     ]
    }
   ],
   "source": [
    "users = users_dataset\n",
    "products = products_dataset\n",
    "\n",
    "data = prepare_data(users, products) # delete\n",
    "users, products = data.keep_useful_elements()\n",
    "train, test = data.train_test_generator()\n",
    "unique_product_ids, unique_user_ids = data.pass_unique()\n",
    "\n",
    "pre_model = modelAndLoss(unique_product_ids, unique_user_ids, products)\n",
    "user_model, product_model = pre_model.implement_model()\n",
    "task = pre_model.metrics_loss()\n",
    "product_model\n",
    "\n",
    "model = fitAndEvaluateModel(user_model, product_model, train, test)\n",
    "model.create_model()\n",
    "model.compile_model()\n",
    "model_ = model.fit_model()\n",
    "# model_ = model.evaluate_model()\n",
    "# model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9406822-ac14-48dc-b922-029cd8e2d00c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9747aaf9-8445-45e4-90d7-a614cfdb65b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 42: [b'2' b'2' b'2']\n"
     ]
    }
   ],
   "source": [
    "titles, index = make_predictions(model_, products, product_model)\n",
    "print(f\"Recommendations for user 42: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970ee3bf-6f54-4d77-bae1-bbe5ef2799d7",
   "metadata": {},
   "source": [
    "# Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c61606af-202c-407b-8cd4-eb771a813237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Lenovo\\Desktop\\intern\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Lenovo\\Desktop\\intern\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: [b'243' b'243' b'243']\n"
     ]
    }
   ],
   "source": [
    "# Export the query model.\n",
    "x = ''\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    path = os.path.join(tmp, \"model\")\n",
    "\n",
    "    # Save the index.\n",
    "    tf.saved_model.save(index, p)\n",
    "\n",
    "    # Load it back; can also be done in TensorFlow Serving.\n",
    "    loaded = tf.saved_model.load(p)\n",
    "\n",
    "    # Pass a user id in, get top predicted movie titles back.\n",
    "    scores, titles = loaded([\"90\"])\n",
    "    x = path\n",
    "    print(f\"Recommendations: {titles[0][:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f721285-d674-4720-91e7-1ce192590c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Lenovo\\\\AppData\\\\Local\\\\Temp\\\\tmp4o57w0gs\\\\model'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 'C:\\\\Users\\\\Lenovo\\\\Desktop\\\\intern'\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c2001a7-9c6f-4a47-aca4-e4d6df6e27c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: C:\\Users\\Lenovo\\AppData\\Local\\Temp\\tmph0hfa9g7\\model\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load it back; can also be done in TensorFlow Serving.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# path = 'C:\\\\Users\\\\Lenovo\\\\AppData\\\\Local\\\\Temp\\\\tmput2dmwc9\\\\model'\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m loaded \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Pass a user id in, get top predicted movie titles back.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m scores, titles \u001b[38;5;241m=\u001b[39m loaded([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m9\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:782\u001b[0m, in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(export_dir, os\u001b[38;5;241m.\u001b[39mPathLike):\n\u001b[0;32m    781\u001b[0m   export_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(export_dir)\n\u001b[1;32m--> 782\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mload_partial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:887\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tags, \u001b[38;5;28mset\u001b[39m):\n\u001b[0;32m    883\u001b[0m   \u001b[38;5;66;03m# Supports e.g. tags=SERVING and tags=[SERVING]. Sets aren't considered\u001b[39;00m\n\u001b[0;32m    884\u001b[0m   \u001b[38;5;66;03m# sequences for nest.flatten, so we put those through as-is.\u001b[39;00m\n\u001b[0;32m    885\u001b[0m   tags \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(tags)\n\u001b[0;32m    886\u001b[0m saved_model_proto, debug_info \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 887\u001b[0m     \u001b[43mloader_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_saved_model_with_debug_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    890\u001b[0m     saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject_graph_def\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    891\u001b[0m   metrics\u001b[38;5;241m.\u001b[39mIncrementReadApi(_LOAD_V2_LABEL)\n",
      "File \u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:57\u001b[0m, in \u001b[0;36mparse_saved_model_with_debug_info\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_saved_model_with_debug_info\u001b[39m(export_dir):\n\u001b[0;32m     45\u001b[0m   \u001b[38;5;124;03m\"\"\"Reads the savedmodel as well as the graph debug info.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m    parsed. Missing graph debug info file is fine.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m   saved_model \u001b[38;5;241m=\u001b[39m \u001b[43mparse_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m   debug_info_path \u001b[38;5;241m=\u001b[39m file_io\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m     60\u001b[0m       saved_model_utils\u001b[38;5;241m.\u001b[39mget_debug_dir(export_dir),\n\u001b[0;32m     61\u001b[0m       constants\u001b[38;5;241m.\u001b[39mDEBUG_INFO_FILENAME_PB)\n\u001b[0;32m     62\u001b[0m   debug_info \u001b[38;5;241m=\u001b[39m graph_debug_info_pb2\u001b[38;5;241m.\u001b[39mGraphDebugInfo()\n",
      "File \u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:115\u001b[0m, in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot parse file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_pbtxt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    116\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel file does not exist at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexport_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PB\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: C:\\Users\\Lenovo\\AppData\\Local\\Temp\\tmph0hfa9g7\\model\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "# Load it back; can also be done in TensorFlow Serving.\n",
    "\n",
    "# path = 'C:\\\\Users\\\\Lenovo\\\\AppData\\\\Local\\\\Temp\\\\tmput2dmwc9\\\\model'\n",
    "loaded = tf.saved_model.load(path)\n",
    "\n",
    "# Pass a user id in, get top predicted movie titles back.\n",
    "scores, titles = loaded([\"9\"])\n",
    "x = path\n",
    "print(f\"Recommendations: {titles[0][:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5499d41-eb65-4f67-b171-46cb7ca57d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Lenovo\\\\AppData\\\\Local\\\\Temp\\\\tmput2dmwc9\\\\model'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ab24467-93e1-4c19-b50f-8a16de69fe3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 305s 60s/step - factorized_top_k/top_1_categorical_accuracy: 0.0054 - factorized_top_k/top_5_categorical_accuracy: 0.0054 - factorized_top_k/top_10_categorical_accuracy: 0.0054 - factorized_top_k/top_50_categorical_accuracy: 0.0058 - factorized_top_k/top_100_categorical_accuracy: 0.0063 - loss: 31634.5033 - regularization_loss: 0.0000e+00 - total_loss: 31634.5033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.userProductModel at 0x21597962370>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c7f396-5825-497a-a811-37cb7d2b975b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
